version: "1.0"
description: "Post-prompt for ping_llm_provider - LLM provider health check"
config:
  model: ""
  temperature: 0.3
  max_tokens: 2000
messages:
  - role: system
    content: |
      Ты проверил доступность LLM провайдера (OpenRouter, OpenAI, Zai, DeepSeek).

      Представь результат в формате:

      ## Ключевые метрики
      - Провайдер: [name]
      - Статус: [✅ доступен / ❌ недоступен]
      - Задержка: [X]ms
      - Время проверки: [timestamp]

      ## Детали проверки
      - API ключ: [валидный / неверный]
      - Endpoint: [URL]
      - Ошибка: [если есть]

      ## Результат диагностики
      **Если доступен:**
      ✅ Провайдер работает нормально
      - Можно выполнять запросы
      - Задержка в пределах нормы

      **Если недоступен:**
      ❌ Обнаружены проблемы

      Возможные причины:
      1. Неверный API ключ
      2. Сетевые проблемы
      3. Провайдер временно недоступен

      Рекомендуемые действия:
      1. Проверь API ключ в config.yaml
      2. Проверь интернет соединение
      3. Попробуй позже

# Poncho AI: Комплексный анализ подходов и архитектуры проекта

## 1. Назначение и функциональность проекта

Poncho AI — это LLM-agnostic, Tool-centric framework на Go. Он предоставляет структуру для создания агентов, беря на себя рутину (промпт-инжиниринг, JSON-валидацию, историю), и оставляет разработчику только реализацию чистой бизнес-логики в виде изолированных инструментов.

Poncho AI — это многофункциональная AI-платформа, предназначенная для автоматизации процессов работы с Wildberries и Ozon (крупные российские маркетплейс-платформы). Проект объединяет в себе возможности обработки изображений, работы с облачным хранилищем S3, интеграцию с различными AI-моделями и предоставляет инструменты для управления товарными карточками, например, подготовкой их описания с помощью PLM на основе входящих данных производственного, маркетингового и e-commers характера. 

Основные функциональные возможности:
- **AI-ассистент** с TUI-интерфейсом на основе Bubble Tea
- **Загрузка файлов** из S3 хранилища по настраиваемым правилам
- **Интеграция с Wildberries API** для работы с каталогами, категориями товаров и справочниками
- **Мультимодальная обработка** изображений и текста через различные AI-провайдеры
- **Система инструментов (Tools)** для расширения функциональности LLM
- **Управление промптами** с шаблонизацией и рендерингом

## 2. Основные компоненты и их взаимосвязи

### Архитектурные слои:

#### **Прикладной слой (cmd/)**
- `cmd/poncho/` — основное приложение с TUI-интерфейсом
- `cmd/simple-llm-util/` — CLI-утилита для прямого взаимодействия с LLM
- `cmd/list-bucket/` — утилита для инспекции S3 бакета
- `cmd/tool-usage-example/` — пример использования AI-агента с инструментами

#### **Внутренняя логика (internal/)**
- `internal/app/state.go` — глобальное состояние приложения
- `internal/ui/` — компоненты пользовательского интерфейса (model, view, update, styles)

#### **Библиотечные пакеты (pkg/)**
- `pkg/config/` — управление конфигурацией с поддержкой ENV-переменных
- `pkg/llm/` — абстракция над AI-провайдерами с OpenAI-совместимым адаптером
- `pkg/factory/` — фабрика для создания LLM-провайдеров
- `pkg/s3storage/` — клиент для работы с S3-совместимым хранилищем
- `pkg/wb/` — клиент для Wildberries Content API
- `pkg/tools/` — реестр инструментов для расширения функциональности
- `pkg/classifier/` — движок классификации файлов
- `pkg/prompt/` — система управления промптами с шаблонизацией

### Взаимосвязи компонентов:

```
┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐
│   CLI/TUI Apps  │───▶│  Global State    │───▶│  Config Loader  │
└─────────────────┘    └──────────────────┘    └─────────────────┘
         │                       │                       │
         ▼                       ▼                       ▼
┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐
│  UI Components  │◀───│   Command Engine │───▶│  Tool Registry  │
└─────────────────┘    └──────────────────┘    └─────────────────┘
         │                       │                       │
         ▼                       ▼                       ▼
┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐
│  S3 Storage     │◀───│   File Classifier│───▶│  WB API Client  │
└─────────────────┘    └──────────────────┘    └─────────────────┘
         │                       │                       │
         ▼                       ▼                       ▼
┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐
│  LLM Providers  │◀───│  Prompt Engine   │───▶│  AI Tools       │
└─────────────────┘    └──────────────────┘    └─────────────────┘
```

## 3. Архитектурный подход и его уникальные особенности

### **Гибридная архитектура с доминированием TUI**

Poncho AI использует **TUI-first подход** на основе фреймворка Bubble Tea, что является нетипичным решением для AI-платформ. Этот подход обеспечивает:

- **Высокую производительность** без накладных расходов веб-интерфейса
- **Эффективное использование ресурсов** при работе с большими объемами данных
- **Удобство для разработчиков** и технических специалистов
- **Быструю навигацию** и управление через клавиатурные сокращения

### **Модульная плагинная архитектура**

Ключевая особенность — **система инструментов (Tools)**, которая позволяет:

- **Расширять функциональность** без изменения основного кода
- **Интегрировать внешние API** через унифицированный интерфейс
- **Создавать AI-агентов** с возможностью вызова функций
- **Динамически регистрировать** новые инструменты в реестре

### **Абстракция над AI-провайдерами**

Архитектура обеспечивает **универсальный доступ** к различным AI-моделям:

- **OpenAI-совместимый адаптер** покрывает 99% современных API
- **Фабрика провайдеров** для динамического создания клиентов
- **Унифицированный формат запросов** и ответов
- **Поддержка мультимодальности** (текст + изображения)

### **Конфигурируемая классификация файлов**

**Движок классификации** с настраиваемыми правилами позволяет:

- **Гибко настраивать** правила классификации через YAML
- **Использовать glob-паттерны** для фильтрации файлов
- **Валидировать обязательные** типы файлов
- **Автоматически организовывать** файлы по категориям

## 4. Ключевые паттерны и архитектурные решения

### **The Elm Architecture (TEA - Model-View-Update)**
Используется в UI-компонентах:
- **Model** — состояние приложения
- **View** — рендеринг интерфейса
- **Update** — обработка событий и команд
- **Cmd** — асинхронные операции

### **Factory Pattern**
Применяется для создания LLM-провайдеров:
```go
func NewLLMProvider(cfg config.ModelDef) (llm.Provider, error)
```

### **Registry Pattern**
Используется для управления инструментами:
```go
type Registry struct {
    mu    sync.RWMutex
    tools map[string]Tool
}
```

### **Strategy Pattern**
Реализован в классификаторе файлов:
- Различные стратегии сопоставления паттернов
- Гибкая система правил классификации

### **Adapter Pattern**
OpenAI-адаптер обеспечивает совместимость с различными AI API:
```go
type Client struct {
    apiKey  string
    baseURL string
    http    *http.Client
}
```

### **Template Method Pattern**
Система промптов с шаблонизацией:
```go
func (pf *PromptFile) RenderMessages(data interface{}) ([]Message, error)
```

### **Rate Limiting Pattern**
В WB API клиенте реализовано ограничение запросов:
```go
limiter: rate.NewLimiter(r, BurstLimit)
```

## 5. Управление конфигурацией и зависимостями

### **Централизованная конфигурация**

Конфигурация управляется через `pkg/config/` с поддержкой:
- **YAML-формат** для человекочитаемости
- **ENV-переменные** с синтаксисом `${VAR}`
- **Валидация** обязательных полей
- **Типизация** всех конфигурационных параметров

Структура конфигурации:
```yaml
models:          # Настройки AI-моделей
tools:           # Конфигурация инструментов
s3:              # Параметры S3-хранилища
image_processing: # Настройки обработки изображений
app:             # Общие настройки приложения
file_rules:      # Правила классификации файлов
wb:              # Настройки Wildberries API
```

### **Управление зависимостями**

**Go Modules** с четкой структурой зависимостей:
- **Основные зависимости**: Bubble Tea (TUI), MinIO (S3), YAML
- **AI-интеграция**: OpenAI-совместимый HTTP-клиент
- **Rate limiting**: golang.org/x/time/rate
- **Валидация**: встроенные средства Go

### **Зависимости по слоям архитектуры:**

1. **UI слой**: github.com/charmbracelet/bubbletea, github.com/charmbracelet/lipgloss
2. **Хранилище**: github.com/minio/minio-go/v7
3. **Конфигурация**: gopkg.in/yaml.v3
4. **HTTP клиенты**: стандартная библиотека net/http
5. **Rate limiting**: golang.org/x/time/rate

### **Уникальные особенности управления зависимостями:**

- **Минималистичный подход** — использование стандартной библиотеки там, где возможно
- **OpenAI-совместимость** — один адаптер для множества провайдеров
- **Легковесные клиенты** — отказ от тяжелых SDK в пользу простых HTTP-клиентов
- **Модульная структура** — четкое разделение зависимостей по пакетам

## Правила для разработки
Poncho AI - фреймворк, архитектурная задача которого не просто  построить простого бота, а платформу, в которую другие разработчики (или я сам в будущем) будут "втыкать" новые инструменты и логику, не переписывая ядро.

Вот архитектурная выжимка именно с точки зрения Framework Design, основанная на основных идеях.

Poncho AI Framework: Architectural Design Principles
1. Абстракция Инструментов (Tool Definition Interface)
Фреймворк не должен знать жестко о конкретных инструментах (типа Wildberries). Он должен уметь работать с любым инструментом, который соответствует контракту.

Принцип: ToolDef (Definition) как универсальный контракт.

Реализация:

Фреймворк ожидает структуру, содержащую метаданные (Name, Description) и схему аргументов.

Инверсия управления: Пользователь фреймворка регистрирует инструменты, а Фреймворк сам решает, как презентовать их LLM (генерирует системный промпт) и как парсить ответ.

2. Динамическая Генерация Контекста (Dynamic Prompt Engineering)
Одна из задач фреймворка — скрыть от разработчика сложность формирования промптов.

Логика: Ядро фреймворка (RunAgentStep или аналог) принимает список []ToolDef.

Автоматизация: Фреймворк сам итерируется по списку и собирает описание API для LLM.

Почему это важно: Разработчику инструмента не нужно лезть в системный промпт и писать "У тебя есть инструмент X...". Он просто регистрирует структуру, а фреймворк обновляет "инструкцию" для AI на лету.

3. Протокол Взаимодействия (Framework-Level Protocol)
Фреймворк диктует жесткий протокол общения с LLM, чтобы гарантировать предсказуемость.

JSON-RPC Style: Фреймворк навязывает модели формат ответа {"tool": "name", "args": ...}.

Middleware Очистки: Тот самый cleanJsonBlock — это не просто утилита, это Middleware слой.

Задача: Входящий "сырой" ответ от LLM проходит через слой санитайзеров фреймворка, прежде чем попасть в роутер исполнения. Это защищает бизнес-логику от галлюцинаций модели (markdown-оберток, лишнего текста).

4. Модульность и Структура Пакетов
Судя по путям (pkg/tools/std), фреймворк предполагает наличие "Стандартной библиотеки".

pkg/tools/std: Встроенные инструменты общего назначения (калькулятор, веб-серч и т.д.).

User Space: Пользователь фреймворка может создавать свои пакеты с инструментами, аналогичные std, и просто импортировать их.

Изоляция: Код инструмента (бизнес-логика WB) полностью отделен от кода агента (LLM loops).

5. Обработка ошибок и валидация (Resilience)
Фреймворк берет на себя ответственность за "глупые" ошибки модели.

Если модель прислала битый JSON — фреймворк должен это перехватить (ошибка string literal, которую мы чинили — часть этого механизма).

В идеале фреймворк должен иметь механизм "Retry": если JSON не спарсился, фреймворк сам может отправить модели сообщение об ошибке, не роняя программу.

## Poncho AI Framework: Architectural Design Principles
1. Tooling Layer (Уровень Инструментов)
Инструменты — это граждане первого класса. Фреймворк не реализует логику сам, он оркестрирует исполнение.

Контракт Tool (Interface)
Основа расширяемости. Любой код может стать инструментом, если реализует этот интерфейс.

Decoupling: Инструмент принимает argsJSON string. Это значит, что ядро фреймворка не занимается десериализацией в конкретные структуры. Это ответственность самого инструмента.

Принцип: "Raw In, String Out". Фреймворк передает сырые данные от модели прямо в инструмент.

go
type Tool interface {
    Definition() ToolDefinition             // Метаданные для LLM
    Execute(ctx, argsJSON string) (string, error) // Изолированная логика
}
Registry (Реестр)
Центральная точка доступа.

Pattern: Service Locator / Registry.

Механика: Инструменты регистрируются при старте приложения (tools.Register(...)). При вызове фреймворк ищет инструмент по имени (Find(name)). Это позволяет динамически включать/выключать наборы функций (например, разные наборы для разных ролей бота).

2. LLM Abstraction Layer (Слой Абстракции Модели)
Фреймворк изолирует бизнес-логику от конкретного провайдера (OpenAI, DeepSeek и т.д.).

Interface: Provider (в pkg/llm).

Метод Generate(messages []Message) (string, error).

Фреймворк работает с универсальной структурой Message (Role, Content), а не с проприетарными типами SDK (типа openai.ChatCompletionRequest).

Адаптеры: В pkg/llm/openai лежит реализация адаптера, который конвертирует внутренние сообщения Poncho в формат OpenAI API.

3. State Management (Управление Состоянием)
Фреймворк — это Stateful система.

AppState: Структура, хранящая всю историю диалога (History).

Thread Safety: В state.go видно использование мьютексов (sync.RWMutex), что говорит о готовности фреймворка к конкурентному доступу (например, веб-сервер, обслуживающий несколько чатов).

Контекст: История не просто хранится, она передается в LLM на каждом шаге цикла.

4. Execution Pipeline (Цикл Исполнения)
Основной цикл работы агента (RunAgentStep в main.go) — это конвейер:

Context Construction: Сборка истории + Системного промпта (с динамическим списком тулов).

Inference: Вызов LLM.

Sanitization: Очистка ответа (middleware cleanJsonBlock).

Routing: Парсинг JSON -> Поиск инструмента в Registry -> Вызов Execute.

Feedback: Результат выполнения инструмента добавляется в историю как сообщение от роли tool (или system), замыкая цикл.

5. DX & Configuration (Опыт разработчика)
Config-First: Все настройки (ключи, URL, модели) вынесены в YAML (config.yaml). Код не содержит хардкода.

Простота входа: Чтобы добавить новую фичу, разработчику нужно:

Написать структуру, реализующую Tool.

Зарегистрировать её одной строкой в main.

Всё остальное (промпты, парсинг, HTTP) фреймворк сделает сам.

## Заключение

Poncho AI представляет собой **инновационную AI-платформу** с уникальным TUI-подходом, модульной архитектурой и высокой степенью настраиваемости. Проект демонстрирует передовые практики Go-разработки, включая четкое разделение ответственности, использование паттернов проектирования и эффективное управление зависимостями. Архитектура платформы обеспечивает масштабируемость, расширяемость и удобство поддержки, что делает ее отличным примером современной разработки AI-систем.